{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed552900",
   "metadata": {},
   "source": [
    "# Working with Complex Types\n",
    "\n",
    "Spark allows working with types other than numbers, booleans and text. It is also possible to use data structures (lists, maps) and nested types (structs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6be9d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "22/11/07 01:23:26 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"/work/data/retail-data/all/*.csv\")\\\n",
    "  .coalesce(5)\n",
    "df.cache()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcaf1bb",
   "metadata": {},
   "source": [
    "## Date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36238ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|   InvoiceDate|\n",
      "+--------------+\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "|12/1/2010 8:26|\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('InvoiceDate').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db43c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-------------------+\n",
      "|   InvoiceDate|      date|               time|\n",
      "+--------------+----------+-------------------+\n",
      "|12/1/2010 8:26|2010-01-12|2010-01-12 08:26:00|\n",
      "|12/1/2010 8:26|2010-01-12|2010-01-12 08:26:00|\n",
      "|12/1/2010 8:26|2010-01-12|2010-01-12 08:26:00|\n",
      "|12/1/2010 8:26|2010-01-12|2010-01-12 08:26:00|\n",
      "|12/1/2010 8:26|2010-01-12|2010-01-12 08:26:00|\n",
      "+--------------+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, to_timestamp\n",
    "date_time_format = \"dd/M/yyyy h:mm\"\n",
    "df_with_datetime = df.select('InvoiceDate', \n",
    "                             to_date(col('InvoiceDate'), date_time_format).alias('date'),\n",
    "                             to_timestamp(col('InvoiceDate'), date_time_format).alias('time'))\n",
    "df_with_datetime.show(5)\n",
    "df_with_datetime.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb73e8b",
   "metadata": {},
   "source": [
    "### Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fdf6c869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          struct_col|\n",
      "+--------------------+\n",
      "|[17850, United Ki...|\n",
      "|[17850, United Ki...|\n",
      "|[17850, United Ki...|\n",
      "|[17850, United Ki...|\n",
      "|[17850, United Ki...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- struct_col: struct (nullable = false)\n",
      " |    |-- CustomerID: integer (nullable = true)\n",
      " |    |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_struct = df.selectExpr('(CustomerID, Country) as struct_col')\n",
    "df_with_struct.show(5)\n",
    "df_with_struct.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d120a7b",
   "metadata": {},
   "source": [
    "Selecting struct's fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bef668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|       Country|\n",
      "+--------------+\n",
      "|United Kingdom|\n",
      "|United Kingdom|\n",
      "|United Kingdom|\n",
      "|United Kingdom|\n",
      "|United Kingdom|\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_struct.select('struct_col.Country').show(5)\n",
    "# or df_with_struct.select(col('struct_field').getField('Country'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e21a2",
   "metadata": {},
   "source": [
    "### Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c885d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         Description|           array_col|\n",
      "+--------------------+--------------------+\n",
      "|WHITE HANGING HEA...|[WHITE, HANGING, ...|\n",
      "| WHITE METAL LANTERN|[WHITE, METAL, LA...|\n",
      "|CREAM CUPID HEART...|[CREAM, CUPID, HE...|\n",
      "|KNITTED UNION FLA...|[KNITTED, UNION, ...|\n",
      "|RED WOOLLY HOTTIE...|[RED, WOOLLY, HOT...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Description: string (nullable = true)\n",
      " |-- array_col: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "df_with_array = df.select(col('Description'), split(col(\"Description\"), \" \").alias('array_col'))\n",
    "df_with_array.show(5)\n",
    "df_with_array.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e28d0b",
   "metadata": {},
   "source": [
    "Selecting element from arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0145dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------------+\n",
      "|array_col[0]|array_col[2]|array_col[1000]|\n",
      "+------------+------------+---------------+\n",
      "|       WHITE|       HEART|           null|\n",
      "|       WHITE|     LANTERN|           null|\n",
      "|       CREAM|      HEARTS|           null|\n",
      "|     KNITTED|        FLAG|           null|\n",
      "|         RED|      HOTTIE|           null|\n",
      "+------------+------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_array.selectExpr('array_col[0]', 'array_col[2]', 'array_col[1000]').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1d686",
   "metadata": {},
   "source": [
    "Array length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1dccfae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|size(array_col)|\n",
      "+---------------+\n",
      "|              5|\n",
      "|              3|\n",
      "|              5|\n",
      "|              6|\n",
      "|              5|\n",
      "+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size\n",
    "df_with_array.select(size('array_col')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61269059",
   "metadata": {},
   "source": [
    "Array contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1b654b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------------------+\n",
      "|         Description|array_contains(array_col, WHITE)|\n",
      "+--------------------+--------------------------------+\n",
      "|WHITE HANGING HEA...|                            true|\n",
      "| WHITE METAL LANTERN|                            true|\n",
      "|CREAM CUPID HEART...|                           false|\n",
      "|KNITTED UNION FLA...|                           false|\n",
      "|RED WOOLLY HOTTIE...|                            true|\n",
      "+--------------------+--------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "df_with_array.select(col('Description'), array_contains('array_col', 'WHITE')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcdcc5e",
   "metadata": {},
   "source": [
    "Explode: explode turns elements of an array into rows, if more columns exists in the same array's row, the valus are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5f53d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|    col|         Description|\n",
      "+-------+--------------------+\n",
      "|  WHITE|WHITE HANGING HEA...|\n",
      "|HANGING|WHITE HANGING HEA...|\n",
      "|  HEART|WHITE HANGING HEA...|\n",
      "|T-LIGHT|WHITE HANGING HEA...|\n",
      "| HOLDER|WHITE HANGING HEA...|\n",
      "|  WHITE| WHITE METAL LANTERN|\n",
      "|  METAL| WHITE METAL LANTERN|\n",
      "|LANTERN| WHITE METAL LANTERN|\n",
      "|  CREAM|CREAM CUPID HEART...|\n",
      "|  CUPID|CREAM CUPID HEART...|\n",
      "| HEARTS|CREAM CUPID HEART...|\n",
      "|   COAT|CREAM CUPID HEART...|\n",
      "| HANGER|CREAM CUPID HEART...|\n",
      "|KNITTED|KNITTED UNION FLA...|\n",
      "|  UNION|KNITTED UNION FLA...|\n",
      "|   FLAG|KNITTED UNION FLA...|\n",
      "|    HOT|KNITTED UNION FLA...|\n",
      "|  WATER|KNITTED UNION FLA...|\n",
      "| BOTTLE|KNITTED UNION FLA...|\n",
      "|    RED|RED WOOLLY HOTTIE...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df_with_array.select(explode('array_col'), 'Description').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc055778",
   "metadata": {},
   "source": [
    "### Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dfc56938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------------------------------------------------+\n",
      "|CustomerID|map_col                                                         |\n",
      "+----------+----------------------------------------------------------------+\n",
      "|17850     |[WHITE HANGING HEART T-LIGHT HOLDER -> 536365, 17850 -> 85123A] |\n",
      "|17850     |[WHITE METAL LANTERN -> 536365, 17850 -> 71053]                 |\n",
      "|17850     |[CREAM CUPID HEARTS COAT HANGER -> 536365, 17850 -> 84406B]     |\n",
      "|17850     |[KNITTED UNION FLAG HOT WATER BOTTLE -> 536365, 17850 -> 84029G]|\n",
      "|17850     |[RED WOOLLY HOTTIE WHITE HEART. -> 536365, 17850 -> 84029E]     |\n",
      "+----------+----------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- map_col: map (nullable = false)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import create_map\n",
    "df_with_map = df.select(\n",
    "    'CustomerID',\n",
    "    create_map(col(\"Description\"), col(\"InvoiceNo\"), col('CustomerID'), col('StockCode')).\\\n",
    "        alias(\"map_col\"))\n",
    "df_with_map.show(5, truncate=False)\n",
    "df_with_map.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596bf52",
   "metadata": {},
   "source": [
    "Querying key in map using a literal key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aba26d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|map_col[WHITE METAL LANTERN]|\n",
      "+----------------------------+\n",
      "|                        null|\n",
      "|                      536365|\n",
      "|                        null|\n",
      "|                        null|\n",
      "|                        null|\n",
      "+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_map.selectExpr('map_col[\"WHITE METAL LANTERN\"]').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000aaa9",
   "metadata": {},
   "source": [
    "Using a colum value as the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76d80f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|map_col[CAST(CustomerID AS STRING)]|\n",
      "+-----------------------------------+\n",
      "|                             85123A|\n",
      "|                              71053|\n",
      "|                             84406B|\n",
      "|                             84029G|\n",
      "|                             84029E|\n",
      "+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_map.selectExpr('map_col[CustomerID]').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25354d",
   "metadata": {},
   "source": [
    "Exploding a map: each key-value pair is turned into a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "002f9dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                 key| value|\n",
      "+--------------------+------+\n",
      "|WHITE HANGING HEA...|536365|\n",
      "|               17850|85123A|\n",
      "| WHITE METAL LANTERN|536365|\n",
      "|               17850| 71053|\n",
      "|CREAM CUPID HEART...|536365|\n",
      "|               17850|84406B|\n",
      "|KNITTED UNION FLA...|536365|\n",
      "|               17850|84029G|\n",
      "|RED WOOLLY HOTTIE...|536365|\n",
      "|               17850|84029E|\n",
      "|SET 7 BABUSHKA NE...|536365|\n",
      "|               17850| 22752|\n",
      "|GLASS STAR FROSTE...|536365|\n",
      "|               17850| 21730|\n",
      "|HAND WARMER UNION...|536366|\n",
      "|               17850| 22633|\n",
      "|HAND WARMER RED P...|536366|\n",
      "|               17850| 22632|\n",
      "|ASSORTED COLOUR B...|536367|\n",
      "|               13047| 84879|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_map.selectExpr('explode(map_col)').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
