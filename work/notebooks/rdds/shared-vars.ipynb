{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3e8860",
   "metadata": {},
   "source": [
    "# Shared Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda64979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[8] at readRDDFromFile at PythonRDD.scala:262"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCollection = '''Please could you stop the noise?\n",
    "I'm trying to get some rest\n",
    "From all the unborn chicken\n",
    "Voices in my head\n",
    "What's that?\n",
    "(I may be paranoid, but not an android)\n",
    "What's that?\n",
    "(I may be paranoid, but not an android)\n",
    "When I am king\n",
    "You will be first against the wall\n",
    "With your opinion\n",
    "Which is of no consequence at all'''.replace('\\n', ' ').split(' ')\n",
    "words = spark.sparkContext.parallelize(myCollection, 3) # the second parameter specifies the number of partitions\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc8253a",
   "metadata": {},
   "source": [
    "## Broadcast variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca18418",
   "metadata": {},
   "source": [
    "Create a broadcast variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc988e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  {'paranoid,': 1000, 'android)': 750, 'chicken': 500, 'king': 250}\n"
     ]
    }
   ],
   "source": [
    "# define a regular variable, it will be used to enrich data from the RDD\n",
    "words_weights = {\"paranoid,\":1000, \"android)\":750, \"chicken\":500, \"king\":250}\n",
    "\n",
    "#convert to broadcast variable\n",
    "broadcast_weights = spark.sparkContext.broadcast(words_weights)\n",
    "\n",
    "# get broadcast variable's value:\n",
    "print('Value: ', broadcast_weights.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf3622",
   "metadata": {},
   "source": [
    "Reference broadcast variable from an executor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29924e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1000, 'paranoid,'),\n",
       " (1000, 'paranoid,'),\n",
       " (750, 'android)'),\n",
       " (750, 'android)'),\n",
       " (500, 'chicken'),\n",
       " (250, 'king'),\n",
       " (1, 'Please'),\n",
       " (1, 'could'),\n",
       " (1, 'you'),\n",
       " (1, 'stop')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_weighted_word(word):\n",
    "    weight = broadcast_weights.value.get(word.lower(), 1)\n",
    "    return weight, word\n",
    "\n",
    "w_words = words.map(to_weighted_word)\n",
    "# sort in descending weight order\n",
    "w_words.sortBy(lambda wordPair: -wordPair[0]).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1749a4",
   "metadata": {},
   "source": [
    "## Accumulators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984d492",
   "metadata": {},
   "source": [
    "This example will count flights to and from China using an accumulator.\n",
    "First, load example fights data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05272463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: \n",
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"/work/data/2010-summary.csv\")\n",
    "print('Schema: ')\n",
    "flights.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c940e",
   "metadata": {},
   "source": [
    "Create an unnamed accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "642be4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_china = spark.sparkContext.accumulator(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f22ab",
   "metadata": {},
   "source": [
    "Use accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "395d2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_china_func(flight_row):\n",
    "  dest = flight_row[0]\n",
    "  origin = flight_row[1]\n",
    "  if \"China\" in (origin, dest):\n",
    "    acc_china.add(flight_row[2])\n",
    "    \n",
    "flights.foreach(lambda flight_row: acc_china_func(flight_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25348497",
   "metadata": {},
   "source": [
    "Show accumulator final value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dceed7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_china.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
