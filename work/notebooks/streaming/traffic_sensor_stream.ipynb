{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd49d674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "data = spark.read.load('/work/data/AGOSTO_2022_PARQUET_FINAL')\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8750a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_BOOTSTRAP_SERVERS = \"kafka:9092\"\n",
    "KAFKA_TOPIC = \"traffic_sensor\"\n",
    "SCHEMA = data.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d533576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EQP_ID: long (nullable = true)\n",
      " |-- DATE_TIME: timestamp (nullable = true)\n",
      " |-- MILLISECOND: long (nullable = true)\n",
      " |-- CLASSIFICATION: string (nullable = true)\n",
      " |-- ROAD_LANE: long (nullable = true)\n",
      " |-- ADDRESS_ID: long (nullable = true)\n",
      " |-- ROAD_SPEED: string (nullable = true)\n",
      " |-- VEHICLE_SPEED: string (nullable = true)\n",
      " |-- VEHICLE_LENGTH: string (nullable = true)\n",
      " |-- SERIAL_NUMBER: long (nullable = true)\n",
      " |-- LATITUDE: string (nullable = true)\n",
      " |-- LONGITUDE: string (nullable = true)\n",
      " |-- ADDRESS: string (nullable = true)\n",
      " |-- DIRECTION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea1fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traffic_stream = spark\\\n",
    "    .readStream.format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP_SERVERS)\\\n",
    "    .option(\"subscribe\", KAFKA_TOPIC)\\\n",
    "    .option(\"startingOffsets\", \"earliest\")\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "369a01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_traffic_stream = df_traffic_stream\\\n",
    "    .select(\n",
    "        F.from_json(\n",
    "            # decode string as iso-8859-1\n",
    "            F.decode(F.col(\"value\"), \"iso-8859-1\"),\n",
    "            SCHEMA\n",
    "        ).alias(\"value\")\n",
    "    )\\\n",
    "    .select(\"value.*\")\\\n",
    "    .select(\n",
    "        F.col(\"classification\").alias(\"vehicle_type\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0ebfdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/26 19:07:24 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-06ed80e2-cf57-400f-b4b4-f5e02f48e384. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fc9e0176210>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_traffic_stream.groupBy(\"vehicle_type\")\\\n",
    "    .count()\\\n",
    "    .writeStream\\\n",
    "    .queryName(\"vehicle_type_count\")\\\n",
    "    .outputMode(\"complete\")\\\n",
    "    .format(\"memory\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b337ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72238d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2605c917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>vehicle_type</th><th>count</th></tr>\n",
       "<tr><td>AUTOMÓVEL</td><td>80507</td></tr>\n",
       "<tr><td>INDEFINIDO</td><td>2</td></tr>\n",
       "<tr><td>MOTO</td><td>13609</td></tr>\n",
       "<tr><td>CAMINHÃO / ÔNIBUS </td><td>5882</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------------+-----+\n",
       "|      vehicle_type|count|\n",
       "+------------------+-----+\n",
       "|         AUTOMÓVEL|80507|\n",
       "|        INDEFINIDO|    2|\n",
       "|              MOTO|13609|\n",
       "|CAMINHÃO / ÔNIBUS | 5882|\n",
       "+------------------+-----+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    clear_output(wait=True)\n",
    "    display(spark.sql(\"SELECT * FROM vehicle_type_count\"))\n",
    "    sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
